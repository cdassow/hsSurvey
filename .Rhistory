local({pkg <- select.list(sort(.packages(all.available = TRUE)),graphics=TRUE)
if(nchar(pkg)) library(pkg, character.only=TRUE)})
q()
#Vectors
#Logical
vtrl= c(TRUE,FALSE)
class(vtrl)
vtr2=c(15,85.68938,999999)
class(vtrl)
vtr2
class(vtr2)
vtr3=c(35L,58L,146L)
vtr3
class(vtr3)
vtr4=c(58.467L)
vtr5=c("Hello", FALSE, 65L)
vtr5
class(vtr5)
mtr= matrix(c(5:30),5,5)
mtr= matrix(c(5:29),5,5)
mtr
arr = array(c(1:9),dim = c(3,3,4,2))
arr
vtr7 =c(5.678,32,95,31.6)
vtr8=c("Hey", "How are you?","Thank you")
my list= list(vtr7,vtr8,vtr1)
my list = list(vtr7,vtr8,vtr1)
mylist = list(vtr7,vtr8,vtr1)
mylist = list(vtr7,vtr8,vtr2)
my list
mylist
#dataframe
vtr1 =c(1:5)
vtr2 = c("Neel","jude", "Adam","Adithya","Swetha")
vtr3 = c(15,25,65,145,74)
data.frame(vtr1,vtr2,vtr3)
print(6+9.87)
print(6/9.87)
#modular operation- to get division remainder
print(6%%9.87)
print(22/7)
print(22%%7)
#floor division rounds
print(22%/%7)
var = 25
var1 = 60
print(var==var1)
print(var !=var1)
value1= c(TRUE,FALSE, TRUE, FALSE)
value2= c(FALSE, TRUE, TRUE, FALSE)
print(value1 & value2)
print(value1|value2)
print(value1||value2)
#getting data for hunter
lmb=fishIS[fishIS$lakeID=="HT" & fishIS$species=="largemouth_bass",]
#putting samples into batches for one sampling night of work
#adding a column for batches
lmb$batch=numeric(nrow(lmb))
samp=unique(lmb$sampleID)
samp
#check times to sort batches
lmb$batch[lmb$sampleID%in%samp[1:4]]=1
lmb$batch[lmb$sampleID%in%samp[5:7]]=2
lmb$batch[lmb$sampleID%in%samp[8:11]]=3
lmb$batch[lmb$sampleID%in%samp[12]]=4
lmb$batch[lmb$sampleID%in%samp[13:15]]=5
#collected now
collectedNow=count(lmb, batch)
#marked now
markedNow=lmb%>%
group_by(batch)%>%
filter(clipApply=="AF")%>%
summarize(markedNow=n())
#recaptured now
recapturedNow=lmb%>%
group_by(batch)%>%
filter(clipRecapture=="AF")%>%
summarize(recapturedNow=n())
#combinbing collected, mark, recap data
recapStats=merge(collectedNow, markedNow, by="batch", all=T)
recapStats=merge(recapStats, recapturedNow, by="batch", all=T)
#check for 0s to fill in then run next line
recapStats$recapturedNow[c(2:3)]=0 # no recaps on the first and second samples
#calculate markedPrior for each sample
recapStats$markedPrior=numeric(nrow(recapStats)) #fills in all 0s, which is what we want for the first sample anyway
for(i in 2:nrow(recapStats)){
recapStats$markedPrior[i]=recapStats$markedNow[i-1]+recapStats$markedPrior[i-1]
}
recapStats
# PE, change PE for name of lake
HTpe=schnabel(markedPrior = recapStats$markedPrior, collectedNow = recapStats$n, recapturedNow = recapStats$recapturedNow )
HTpe
#assign to summary dataframe
#lines 54-99 code for lmb PE with lake, change row number for empty spot on PE table
PEs[1,]=c("HT","largemouth_bass", max(HTpe$event), HTpe[max(nrow(HTpe)),3], HTpe[max(nrow(HTpe)),2], HTpe[max(nrow(HTpe)),4])
smb=fishIS[fishIS$lakeID=="HT" & fishIS$species=="smallmouth_bass",]
if(nrow(smb[smb$clipRecapture=="AF",])>5){
#putting samples into batches for one sampling night of work
#adding a column for batches
smb$batch=numeric(nrow(smb))
samp=unique(smb$sampleID)
samp
smb$batch[smb$sampleID%in%samp[1:3]]=1
smb$batch[smb$sampleID%in%samp[4:6]]=2
smb$batch[smb$sampleID%in%samp[7:10]]=3
smb$batch[smb$sampleID%in%samp[11]]=4
smb$batch[smb$sampleID%in%samp[12:14]]=5
#collected now
collectedNow=count(smb, batch)
#marked now
markedNow=smb%>%
group_by(batch)%>%
filter(clipApply=="AF")%>%
summarize(markedNow=n())
#recaptured now
recapturedNow=smb%>%
group_by(batch)%>%
filter(clipRecapture=="AF")%>%
summarize(recapturedNow=n())
#combinbing collected, mark, recap data
recapStats=merge(collectedNow, markedNow, by="batch", all=T)
recapStats=merge(recapStats, recapturedNow, by="batch", all=T)
recapStats$recapturedNow[1:2]=0 # no recaps on the first and second samples
#calculate markedPrior for each sample
recapStats$markedPrior=numeric(nrow(recapStats)) #fills in all 0s, which is what we want for the first sample anyway
for(i in 2:nrow(recapStats)){
recapStats$markedPrior[i]=recapStats$markedNow[i-1]+recapStats$markedPrior[i-1]
}
recapStats
# PE
HTpe=schnabel(markedPrior = recapStats$markedPrior, collectedNow = recapStats$n, recapturedNow = recapStats$recapturedNow )
HTpe
#assign to summary dataframe
PEs[2,]=c("HT","smallmouth_bass", max(HTpe$event), HTpe[max(nrow(HTpe)),3], HTpe[max(nrow(HTpe)),2], HTpe[max(nrow(HTpe)),4])
}else{
PEs[2,]=c("HT","smallmouth_bass", rep(NA,4))
print("not enough SMB captured for PE at HT")
}
#getting data for hunter
lmb=fishIS[fishIS$lakeID=="HT" & fishIS$species=="largemouth_bass",]
#putting samples into batches for one sampling night of work
#adding a column for batches
lmb$batch=numeric(nrow(lmb))
samp=unique(lmb$sampleID)
samp
#check times to sort batches
lmb$batch[lmb$sampleID%in%samp[1:4]]=1
load("~/Fishscapes/fishSamplesIS.csv")
load("~/Fishscapes/fishInfoIS.csv")
setwd("C:/Users/Camille/Desktop/Fishscapes/hsSurvey")
#clear global evnironment
rm(list=ls())
#load any packages we'll need
library(dplyr)
library(ggplot2)
library(dplyr)
library(ggplot2)
gdriveURL <- function(x){
x =
upURL = sub("^[^=]*", "", x)
y1 =  "https://docs.google.com/uc?id"
y2 = "&export=download"
downURL = paste0(y1,upURL,y2)
read.csv(downURL, header = TRUE)
}
creelwall=gdriveURL("https://drive.google.com/open?id=1-d90GHr4iq_xdycFnkis1VKoYqaps00c")
head(creelwall)
#speciescode column, needs to be sorted by county, WBICs
#note the spelling for the species code columns, they vary in DNR data
creelwall <- creelwall[grep("X22",creelwall$Species.Code),]
creelwall <- creelwall[grep("VILAS",creelwall$County),]
creelwall2=gdriveURL("https://drive.google.com/open?id=1pyCKCcAQZiNZz-tX5U2QnZUc79OQEWX2")
head(creelwall2)
#speciescode column, needs to be sorted by county, WBICs
creelwall2 <- creelwall2[grep("X22",creelwall2$speciesCode),]
creelwall2 <- creelwall2[grep("VILAS",creelwall$County),]
#changing column name in first dataset to join with second
names(creelwall)[names(creelwall) == "Species.Code"] <- "speciesCode"
wallinfo=creelwall%>%full_join(creelwall2,by="speciesCode")
