out[,3]/apply(out[,2:4], 1, sum) } )
matplot(Months, outd, type='l', col=1, ylab="Prevalence (I/N)")
matplot(Months, outf, type='l', col=1, ylab="Prevalence (I/N)")
legend('bottomright', legend=S, lty=1:length(S),  bty='n')
#SIR frquency dep.
S <- 4^(0:4)
I <- 1
parmsf <- c(B=1, g=0)
parmsd <- c(B=1/16, g=0)
Months <- seq(0, 8, by=0.1)
outd <- sapply(S, function(s) {out <- ode(c(s,I,R), Months, SIR, parmsd)
out[,3]/apply(out[,2:4], 1, sum) } )
outf <- sapply(S, function(s) {out <- ode(c(s,I,R), Months, SIRf, parmsf)
out[,3]/apply(out[,2:4], 1, sum) } )
matplot(Months, outd, type='l', col=1, ylab="Prevalence (I/N)")
matplot(Months, outf, type='l', col=1, ylab="Prevalence (I/N)")
legend('bottomleft', legend=S, lty=1:length(S),  bty='n')
#6.4
#a)
N <- 10^4; I <- R <- 1; S <- N - I - R
parms <- c(B=.01, g=4)
months <- seq(0,1, by=0.01)
require(deSolve)
SIR.out <- data.frame( ode(c(S,I,R), months, SIR, parms) )
matplot(months, SIR.out[,-1], type='l', lty=1:3, col=1)
legend('right', c('R', 'I', 'S'), lty=3:1, col=3:1, bty='n')
legend('topright', c('R', 'I', 'S'), lty=3:1, col=3:1, bty='n')
#6.4
#a)
N <- 10^4; I <- R <- 1; S <- N - I - R
parms <- c(B=.01, g=4)
months <- seq(0,1, by=0.01)
require(deSolve)
SIR.out <- data.frame( ode(c(S,I,R), months, SIR, parms) )
matplot(months, SIR.out[,-1], type='l', lty=1:3, col=1)
legend('topright', c('R', 'I', 'S'), lty=3:1, col=3:1, bty='n')
#6.4
#a)
N <- 10^4; I <- R <- 1; S <- N - I - R
parms <- c(B=.01, g=4)
months <- seq(0,6, by=0.01)
require(deSolve)
SIR.out <- data.frame( ode(c(S,I,R), months, SIR, parms) )
matplot(months, SIR.out[,-1], type='l', lty=1:3, col=1)
legend('topright', c('R', 'I', 'S'), lty=3:1, col=3:1, bty='n')
#6.4
#a)
N <- 10^4; I <- R <- 1; S <- N - I - R
parms <- c(B=.01, g=4)
months <- seq(0,10, by=0.01)
require(deSolve)
SIR.out <- data.frame( ode(c(S,I,R), months, SIR, parms) )
matplot(months, SIR.out[,-1], type='l', lty=1:3, col=1)
legend('topright', c('R', 'I', 'S'), lty=3:1, col=3:1, bty='n')
#b)
SIRbd <- function(t, y, p) {
S <- y[1]; I <- y[2]; R <- y[3]
with( as.list(p), {
dS.dt <- b*(S+I+R) - B*I*S - m*S
dI.dt <- B*I*S - g*I - m*I
dR.dt <- g*I - m*R
return( list(c(dS.dt, dI.dt, dR.dt)) )
} )
}
N <- 10^6
R <- 0; I <- 1; S <- N - I - R
g <- 1/(13/365)
b <- 1/50
age <- 5
R0 <- 1 + 1/(b*age)
B <- R0 * (g + b) / N
parms <- c(B = B, g = g, b = b, m=b)
years <- seq(0,30, by=.1)
SIRbd.out <- data.frame(ode(c(S=S,I=I,R=R), years, SIRbd, parms, hmax=.01))
matplot(SIRbd.out[,1], sqrt(SIRbd.out[,-1]), type='l', col=1,
lty=1:3, ylab="sqrt(No. of Individuals)", xlab='Years')
legend('right', c('S','I','R'), lty=1:3, bty='n'
SIRbd <- function(t, y, p) {
S <- y[1]; I <- y[2]; R <- y[3]
with( as.list(p), {
dS.dt <- b*(S+I+R) - B*I*S - m*S
dI.dt <- B*I*S - g*I - m*I
dR.dt <- g*I - m*R
return( list(c(dS.dt, dI.dt, dR.dt)) )
} )
}
N <- 10^6
R <- 0; I <- 1; S <- N - I - R
g <- 1/(13/365)
b <- 1/50
age <- 10
R0 <- 1 + 1/(b*age)
B <- R0 * (g + b) / N
parms <- c(B = B, g = g, b = b, m=b)
years <- seq(0,30, by=.1)
SIRbd.out <- data.frame(ode(c(S=S,I=I,R=R), years, SIRbd, parms, hmax=.01))
matplot(SIRbd.out[,1], sqrt(SIRbd.out[,-1]), type='l', col=1,
lty=1:3, ylab="sqrt(No. of Individuals)", xlab='Years')
legend('right', c('S','I','R'), lty=1:3, bty='n'
SIRbd <- function(t, y, p) {
S <- y[1]; I <- y[2]; R <- y[3]
with( as.list(p), {
dS.dt <- b*(S+I+R) - B*I*S - m*S
dI.dt <- B*I*S - g*I - m*I
dR.dt <- g*I - m*R
return( list(c(dS.dt, dI.dt, dR.dt)) )
} )
}
N <- 10^6
R <- 0; I <- 1; S <- N - I - R
g <- 1/(13/365)
b <- 1/50
age <- 50
R0 <- 1 + 1/(b*age)
B <- R0 * (g + b) / N
parms <- c(B = B, g = g, b = b, m=b)
years <- seq(0,30, by=.1)
SIRbd.out <- data.frame(ode(c(S=S,I=I,R=R), years, SIRbd, parms, hmax=.01))
matplot(SIRbd.out[,1], sqrt(SIRbd.out[,-1]), type='l', col=1,
lty=1:3, ylab="sqrt(No. of Individuals)", xlab='Years')
legend('right', c('S','I','R'), lty=1:3, bty='n'
#b)
SIRbd <- function(t, y, p) {
S <- y[1]; I <- y[2]; R <- y[3]
with( as.list(p), {
dS.dt <- b*(S+I+R) - B*I*S - m*S
dI.dt <- B*I*S - g*I - m*I
dR.dt <- g*I - m*R
return( list(c(dS.dt, dI.dt, dR.dt)) )
} )
}
N <- 10^6
R <- 0; I <- 1; S <- N - I - R
g <- 1/(13/365)
b <- 1/50
age <- 50
R0 <- 1 + 1/(b*age)
B <- R0 * (g + b) / N
parms <- c(B = B, g = g, b = b, m=b)
years <- seq(0,30, by=.1)
SIRbd.out <- data.frame(ode(c(S=S,I=I,R=R), years, SIRbd, parms, hmax=.01))
matplot(SIRbd.out[,1], sqrt(SIRbd.out[,-1]), type='l', col=1,
lty=1:3, ylab="sqrt(No. of Individuals)", xlab='Years')
legend('right', c('S','I','R'), lty=1:3, bty='n'
library(deSolve)
SIR.derivs<-function(curr.time, myvars, params) {
gamma = 1.36 #rate at whcih uninfected CD4 lymphocytes arise
tau = 0.2 # proportiono f cells activated
p = 0.1 # proportion of cells bcoming latently infected upon infection
beta = 0.00027 # rate of infection of CD4 lymphocyptes per viron
alpha = 3.6 * 10 ^ -2 # activation rate of latently infected cells
sigma = 2 # removal rat of cell-free virus
delta = 0.33 # removal (death) rate of actively infected CD4
pie = 100 # rate of production of virions by an actively infected cell
u = 1.36 * 10^-3 # HIV-indep death reate of unifected CD4 lymphocytes
R = myvars[1]
L = myvars[2]
E = myvars[3]
V = myvars[4]
dR = gamma * tau - u * R - beta * R * V
dL = p * beta * R * V - u * L - alpha * L
dE = (1-p) * beta * R * V + alpha * L - delta * E
dV = pie * E - sigma * V
return(list(c(dR, dL, dE, dV)))
}
# use libraries to solve SIR equations
library(deSolve)
vars.ini = c(1000, 0, 0, 100) ## initial value of R is 1000 and the initial of V is 100 - based on second paragraph
mytimes = c(1:100) * 0.1 #tau values for which you want to know the output
out = ode(vars.ini, mytimes, SIR.derivs, c(1))
out
plot(out, xlab = "time", ylab = c('R','L','E','V'), main = "Changes in Infection")
setwd("C:/Users/Camille/Desktop/Fishscapes/hsSurvey")
# load function to load data from google drive
source("gdriveURL.R")
library(dplyr)
######## angling CPUE
# load creel data from google drive
creel1=gdriveURL("https://drive.google.com/open?id=1lxUd742QZMXDQunyFBnENKMYZ1XNM_Pc")
creel2=gdriveURL("https://drive.google.com/open?id=1UYhbGH28WXjmi-4BzhfwO4KYwrBCNO2Q")
creel=rbind(creel1,creel2)
# reduce to columns we care about
creel=creel[,c(1,3,6,12,18,25:26,30,36,38)]
# calculate effort
# add zeroes to times with only 2 or 3 digits
creel$timeStart[nchar(creel$timeStart)==3]=paste("0",creel$timeStart[nchar(creel$timeStart)==3],sep="")
creel$timeStart[nchar(creel$timeStart)==2]=paste("00",creel$timeStart[nchar(creel$timeStart)==2],sep="")
creel$timeStart[creel$timeStart=="0"]="0000"
creel=creel[creel$timeStart!="1",]  # 4 entries with "1", so we don't know start time
creel$timeEnd[nchar(creel$timeEnd)==3]=paste("0",creel$timeEnd[nchar(creel$timeEnd)==3],sep="")
creel$timeEnd[nchar(creel$timeStart)==2]=paste("00",creel$timeEnd[nchar(creel$timeEnd)==2],sep="")
creel$timeEnd[creel$timeEnd=="0"]="0000"
creel$boatHrs=0
# remove rows when end time is less than start time (assumes the boat was out over midnight)
creel=creel[strptime(creel$timeEnd,format="%H%M")>=strptime(creel$timeStart,format="%H%M"),]
# calculate difference of time in hours for rows where end time is greater than start time (fishing occurred in one day only)
creel$boatHrs[strptime(creel$timeEnd,format="%H%M")>=strptime(creel$timeStart,format="%H%M")]=as.numeric(difftime(strptime(creel$timeEnd[strptime(creel$timeEnd,format="%H%M")>=strptime(creel$timeStart,format="%H%M")],format="%H%M"),strptime(creel$timeStart[strptime(creel$timeEnd,format="%H%M")>=strptime(creel$timeStart,format="%H%M")],format="%H%M"),units="hours"))
# removing rows with a non-zero notFishingAmt because we don't know what it means to be non-zero...
creel=creel[creel$notFishingAmt==0,]
# remove rows with non-integer anglersAmt
creel=creel[!grepl(".",creel$anglersAmt,fixed=TRUE),]
# remove rows with anglersAmt above 10? (arbitrary choice for now)
creel=creel[creel$anglersAmt<=10,]
# get angler hours of effort from party size and boat hours
creel$anglerHrs=creel$boatHrs*creel$anglersAmt
# remove rows with no species code
creel=creel[!is.na(creel$fishSpeciesCode),]
# remove rows with NA for caughtAmt
creel=creel[!is.na(creel$caughtAmt),]
# remove no effort (anglerHrs==0) rows
creel=creel[creel$anglerHrs>0,]
# calculate angling CPUE
creel$anglingCPUE=creel$caughtAmt/creel$anglerHrs
# removing instances of CPUE >=30 (arbitrary...)
creel=creel[creel$anglingCPUE<30,]
# calculate average angling CPUE and sample size for each lake-year-species combination
lake_yearCPUE=creel %>%
group_by(WBIC,fishSpeciesCode,surveyYear,county) %>%
summarize(meanCPUE=mean(anglingCPUE),
N=n())
lake_yearCPUE=as.data.frame(lake_yearCPUE)
####### electrofishing abundance
bassEF=gdriveURL("https://drive.google.com/open?id=11v8FbT2wnKx_CqUfxu_V9r_8fyCfcdD2")
bassEF=bassEF[,c(1,3,5,13,19,27:29)]
bassEF$CPEkm=bassEF$CPEmile/1.60934   # convert fish per mile to fish per km
bassEF$distanceShockedKm=bassEF$distanceShockedMiles*0.621371 # convert miles to km
lake_yearBASSef= bassEF %>%
group_by(WBIC,species,surveyYear,county) %>%
summarize(meanEF_CPEkm=mean(CPEkm),
totalFishCaught=sum(totalNumberCaughtFish),
totalDistShockedKm=sum(distanceShockedKm),
totalHoursSampled=sum(numberHoursSampled),
std=sd(CPEkm),
N=n())
lake_yearBASSef=as.data.frame(lake_yearBASSef)
panEF=gdriveURL("https://drive.google.com/open?id=1QIqCBQ9gbOgRFUJQbnokwwTZJi5VZZIR")
panEF=panEF[,c(1,3,5,13,19,25:27)]
panEF$CPEkm=panEF$CPEmile/1.60934   # convert fish per mile to fish per km
panEF$distanceShockedKm=panEF$distanceShockedMiles*0.621371 # convert miles to km
lake_yearPANef= panEF %>%
group_by(WBIC,species,surveyYear,county) %>%
summarize(meanEF_CPEkm=mean(CPEkm),
totalFishCaught=sum(totalNumberCaughtFish),
totalDistShockedKm=sum(distanceShockedKm),
totalHoursSampled=sum(numberHoursSampled),
std=sd(CPEkm),
N=n())
lake_yearPANef=as.data.frame(lake_yearPANef)
walleyeEF=gdriveURL("https://drive.google.com/open?id=1DPRROWv6Cf_fP6Z-kE9ZgUfdf_F_jSNT")
walleyeEF=walleyeEF[,c(1,3,5,13,19,23:24,27)]
walleyeEF$CPEkm=walleyeEF$CPEmile/1.60934   # convert fish per mile to fish per km
walleyeEF$distanceShockedKm=walleyeEF$distanceShockedMiles*0.621371 # convert miles to km
#remove commas from total fish caught
walleyeEF$totalNumberCaughtFish=as.numeric(gsub(",","",walleyeEF$totalNumberCaughtFish))
lake_yearWALLef= walleyeEF %>%
group_by(WBIC,species,surveyYear,county) %>%
summarize(meanEF_CPEkm=mean(CPEkm),
totalFishCaught=sum(totalNumberCaughtFish),
totalDistShockedKm=sum(distanceShockedKm),
totalHoursSampled=sum(numberHoursSampled),
std=sd(CPEkm),
N=n())
lake_yearWALLef=as.data.frame(lake_yearWALLef)
##### merge data sets from angling CPUE and electrofishing CPUE to get exact lake-year matches
# convert fishSpeciesCode in lake_yearCPUE to species (name from ef stuff)
lake_yearCPUE$species=""
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="X22"]="WALLEYE"
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="W11"]="SMALLMOUTH BASS"
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="W12"]="LARGEMOUTH BASS"
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="X15"]="YELLOW PERCH"
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="W14"]="BLACK CRAPPIE"
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="W09"]="BLUEGILL"
# trim species without EF data (can we get other species EF data?)
lake_yearCPUE=lake_yearCPUE[lake_yearCPUE$species!="",]
bassJoin=left_join(lake_yearBASSef,lake_yearCPUE,by=c("WBIC"="WBIC","species"="species","surveyYear"="surveyYear", "county"="county"))
bassJoin=bassJoin[!is.na(bassJoin$meanCPUE),]
panJoin=left_join(lake_yearPANef,lake_yearCPUE,by=c("WBIC"="WBIC","species"="species","surveyYear"="surveyYear", "county"="county"))
panJoin=panJoin[!is.na(panJoin$meanCPUE),]
wallJoin=left_join(lake_yearWALLef,lake_yearCPUE,by=c("WBIC"="WBIC","species"="species","surveyYear"="surveyYear", "county"="county"))
wallJoin=wallJoin[!is.na(wallJoin$meanCPUE),]
table(lake_yearCPUE$species)
nrow(lake_yearBASSef)
nrow(bassJoin)
nrow(lake_yearPANef)
nrow(panJoin)
nrow(lake_yearWALLef)
nrow(wallJoin)
bassJoin$logCPUE=log(bassJoin$meanCPUE)
bassJoin$logAbun=log(bassJoin$meanEF_CPEkm)
bassJoin<- bassJoin[is.na(bassJoin$logCPUE)==F,]
bassJoin<- bassJoin[bassJoin$logCPUE!=-Inf,]
wallJoin$logCPUE=log(wallJoin$meanCPUE)
wallJoin$logAbun=log(wallJoin$meanEF_CPEkm)
wallJoin<- wallJoin[wallJoin$logCPUE!=-Inf,]
panJoin$logCPUE=log(panJoin$meanCPUE)
panJoin$logAbun=log(panJoin$meanEF_CPEkm)
panJoin<- panJoin[panJoin$logCPUE!=-Inf,]
LMBplusWall=rbind(bassJoin[bassJoin$species=="LARGEMOUTH BASS",],wallJoin)
#generate linear model to compare hyperstability of
LMBvsWall<-lm(LMBplusWall$logCPUE~LMBplusWall$logAbun*LMBplusWall$species)
summary(LMBvsWall)
#Walleye statistically significant different from LMB hyperstability similar lines on fit
#Bass vs panfish
LMBplusPan=rbind(bassJoin[bassJoin$species=="LARGEMOUTH BASS",],panJoin)
LMBvsPan<- lm(LMBplusPan$logCPUE~LMBplusPan$logAbun*LMBplusPan$species)
summary(LMBvsPan)
#Panfish vs walleye
PanplusWall=rbind(panJoin,wallJoin)
PanvsWall<-lm(PanplusWall$logCPUE~PanplusWall$logAbun*PanplusWall$species)
summary(PanvsWall)
#general linear model for bass, using glm function
fit1<-glm(bassJoin$logCPUE~bassJoin$logAbun)
summary(fit1)
LMBvsSMB<-lm(bassJoin$logCPUE~bassJoin$logAbun*bassJoin$species)
summary(LMBvsSMB)
#both are hyperstable but largemouth bass are more hyperstable
#plotting bass fit and LMBvsSMB fits
plot(x=bassJoin$logAbun,y=bassJoin$logCPUE, main = "Hyperstability of Bass in WI (1995-2016)",
xlab = "Fish density (log ef CPUE)", ylab= "Catch rate (log angling CPUE)" )
abline(LMBvsSMB, col="red")
abline(fit1, col="blue")
legend("bottomright",paste("Fit = ",c("LMB vs SMB","Bass")), lty = 1, col = 1:2, bty = "n")
#ploting model with fit line bass log transformed abund. and CPUE
plot(x=bassJoin$logAbun,y=bassJoin$logCPUE)
abline(fit1)
#normal spcae plot of model fit to the data, exponential(intercept)*x^slope this is qN^B
#coefficients 2 is beta
plot(x=bassJoin$meanEF_CPEkm,y=bassJoin$meanCPUE)
plot(1:65,exp(fit1$coefficients[1])*(1:65)^fit1$coefficients[2], ylab="logCPUE (angling CPUE)", xlab="logAbun (efCPUE)", main = "Hyperstability of bass ")
#can use lines function as well
ggplot(bassJoin,aes(bassJoin$meanEF_CPEkm,bassJoin$meanCPUE))+
geom_point(aes(colour = surveyYear))
ggplot(fit1,aes(bassJoin$meanEF_CPEkm,bassJoin$meanCPUE))+geom_smooth(model=lm)
#model for panfish, fit summary estimate 0.23189
fit2<-glm(panJoin$logCPUE~panJoin$logAbun)
summary(fit2)
#ploting model with fit line log trans. for panfish
plot(x=panJoin$logAbun,y=panJoin$logCPUE)
abline(fit2)
#subsetting to just look at the number of bluegill obs, may be useful later with BLG vs LMB
BLGJoin=panJoin[panJoin$species=="BLUEGILL",]
BLGfit<-glm(BLGJoin$logCPUE~BLGJoin$logAbun)
summary(BLGfit)
LMBplusBLG=rbind(bassJoin[bassJoin$species=="LARGEMOUTH BASS",],BLGJoin)
LMBvsBLG<-lm(LMBplusBLG$logCPUE~LMBplusBLG$logAbun*LMBplusBLG$species)
summary(LMBvsBLG)
#Walleye statistically significant different from LMB hyperstability similar lines on fit
#Bass vs bluegill
BassplusBLG=rbind(bassJoin,BLGJoin)
BassvsBLG<-lm(BassplusBLG$logCPUE~BassplusBLG$logAbun*BassplusBLG$species)
summary(BassvsBLG)#sign differences in effect just largemouth not smallmouth, not signif. diferent from Small
#Bluegill vs walleye
BLGplusWall=rbind(BLGJoin,wallJoin)
BLGvsWall<-lm(BLGplusWall$logCPUE~BLGplusWall$logAbun*BLGplusWall$species)
summary(BLGvsWall)
#normal spcae plot of model fit to the data, qN^B
#coefficients 2 is beta
plot(x=panJoin$meanEF_CPEkm,y=panJoin$meanCPUE)
plot(0:160,exp(fit2$coefficients[1])*(0:160)^fit2$coefficients[2])
# glmodel for walleye, fit summary estimate 0.63073
fit3<-glm(wallJoin$logCPUE~wallJoin$logAbun)
summary(fit3)
#ploting model with fit line bass log transformed abund. and CPUE
plot(x=wallJoin$logAbun,y=wallJoin$logCPUE)
abline(fit3)
#normal spcae plot of model fit to the data, exponential(intercept)*x^slope this is qN^B
#coefficients 2 is beta
plot(x=wallJoin$meanEF_CPEkm,y=wallJoin$meanCPUE)
plot(1:165,exp(fit3$coefficients[1])*(1:165)^fit3$coefficients[2])
### Ploting hyperstability ###
plot(x=1:165,y=exp(fit1$coefficients[1])*(1:165)^fit1$coefficients[2], col='blue', type = "l",ylim = c(0,5),
main = "Hyperstability of fish Species in WI")
lines(1:165,exp(fit2$coefficients[1])*(1:165)^fit2$coefficients[2],col="red")
lines(1:165,exp(fit3$coefficients[1])*(1:165)^fit3$coefficients[2],col="darkgreen")
legend("topright",paste("Fit = ",c("LMB","Panfish","Walleye")), lty = 1:5, col = 1:5)
#using betaBootstrapping R script to calucate betas from model fit to simulated data
### Bootstrapping ####
#make d the dataframe you want, using bass as example
d=panJoin
z=d[!duplicated(d$meanEF_CPEkm),]
agg_logCPUE=log(z$meanCPUE)
#wallJoin and panJoin agg_logCPUE has Inf value, needs to be removed for glm fit
agg_logN=log(z$meanEF_CPEkm)
aggFit_wLK=glm(agg_logCPUE~agg_logN)
#estimate agg fit glm summary 0.42386
summary(aggFit_wLK)
betas=numeric(1000) #betas from model fit to simulated data
ps=numeric(1000) #difference in AIC values between the simulated data model fit and the experimental data model fit
for(i in 1:1000){
pe=rlnorm(n=length(z$meanEF_CPEkm), meanlog = log(z$meanEF_CPEkm))
#rlnorm from chpt 14-45 of RMark book
fit=glm(agg_logCPUE ~ log(pe)+z$meanCPUE)
betas[i]=fit$coefficients[2]
comp=abs(fit$aic - aggFit_wLK$aic)
ps[i]=comp
}
plot(betas, ps)
hist(betas, main = "walleye betas")
hist(ps)
#literature review for building density vilas co., anna marburg
#try model with dummy variable to compare species to each other fit
#lm(loganCPUE~logefCPUE*species), efCPUE + species + efCPUE:species
#B0 + b1efCPUE + B2*species +B3efCPUE scpeies
####Building Density ####
#add in Building density *only for year 2018
buildDensity2018=gdriveURL("https://drive.google.com/open?id=11lPPduqiXIxz00fm6xxFzUA8u9nCOBnN")
#bringing in ntl buidling info for 2001-2004
NTLBuild<- read.csv("NTLBuildDensData(2001-2004).csv")
#fixing column names to join tables
NTLBuild$WBIC=NTLBuild$wbic
NTLBuild$surveyYear=NTLBuild$survey_year
NTLBuild<-NTLBuild[,c(1:4,8:34)]
#joining building density to bass catch + abund info
bassbuildJoin=left_join(bassJoin,NTLBuild, by="WBIC","surveyYear")
bassbuildJoin=bassbuildJoin[!is.na(bassbuildJoin$buildings_per_km),]
#only 24 observations left of 62
#building density numbers for walleye lake yr observations
wallbuildJoin=left_join(wallJoin,NTLBuild,by="WBIC","surveyYear")
wallbuildJoin=wallbuildJoin[!is.na(wallbuildJoin$buildings_per_km),]
#28 observations left of 62
#builing density numbers for panfish lake yr observations
panbuildJoin=left_join(panJoin,NTLBuild,by="WBIC","surveyYear")
panbuildJoin=panbuildJoin[!is.na(panbuildJoin$buildings_per_km),]
#only 12 observations left of 62
#model fits
fit4<-glm(bassbuildJoin$logCPUE~bassbuildJoin$logAbun+bassbuildJoin$logAbun:bassbuildJoin$buildings_per_km)
summary(fit4)#nothing signifcant
fit4.1<-glm(bassbuildJoin$logCPUE~bassbuildJoin$logAbun+bassbuildJoin$logAbun:bassbuildJoin$buildings_per_km_quintile)
summary(fit4.1)#small signif.
#looking at residuals as a function of building density,look at relationship between beta and density
VilasBassFit<-glm(bassbuildJoin$logCPUE~bassbuildJoin$logAbun+bassbuildJoin$logAbun:bassbuildJoin$buildings_per_km_quintile)
plot(bassbuildJoin$buildings_per_km_quintile,residuals(VilasBassFit))
residuals(VilasBassFit)
fit5<-glm(panbuildJoin$logCPUE~panbuildJoin$logAbun+panbuildJoin$logAbun:panbuildJoin$buildings_per_km)
summary(fit5)#not significant
fit5.1<-glm(panbuildJoin$logCPUE~panbuildJoin$logAbun+panbuildJoin$logAbun:panbuildJoin$buildings_per_km)
summary(fit5.1)#not sig.
fit6<-glm(wallbuildJoin$logCPUE~wallbuildJoin$logAbun+wallbuildJoin$logAbun:wallbuildJoin$buildings_per_km)
summary(fit6)#not sig. netiher building quintile
#2001-2016 subset
bassbuildJoin0116<-bassbuildJoin[bassbuildJoin$surveyYear.x>2000 & bassbuildJoin$surveyYear.x<2017,]
#13 obs
wallbuildJoin0116<-wallbuildJoin[wallbuildJoin$surveyYear.x>2000 & wallbuildJoin$surveyYear.x<2017,]
#17 obs
panbuildJoin0116<-panbuildJoin[panbuildJoin$surveyYear.x>2000 & panbuildJoin$surveyYear.x<2017,]
#9 obs
#2001-2004 subset
bassbuildJoin0104<-bassbuildJoin[bassbuildJoin$surveyYear.x>2000 & bassbuildJoin$surveyYear.x<2005,]
#1 obs
wallbuildJoin0104<-wallbuildJoin[wallbuildJoin$surveyYear.x>2000 & wallbuildJoin$surveyYear.x<2005,]
#2 obs
panbuildJoin0104<-panbuildJoin[panbuildJoin$surveyYear.x>2000 & panbuildJoin$surveyYear.x<2005,]
#2 obs
Bassbuild0116<-glm(bassbuildJoin0116$logCPUE~bassbuildJoin0116$logAbun+bassbuildJoin0116$logAbun:bassbuildJoin0116$buildings_per_km)
summary(Bassbuild0116)
summary(Bassbuild0116)
Bassbuild0116<-glm(bassbuildJoin0116$logCPUE~bassbuildJoin0116$logAbun)
summary(Bassbuild0116)
Wallbuild0116<-glm(wallbuildJoin0116$logCPUE~wallbuildJoin0116$logAbun)
summary(Wallbuild0116)
#add in Building density *only for year 2018
buildDensity2018=gdriveURL("https://drive.google.com/open?id=11lPPduqiXIxz00fm6xxFzUA8u9nCOBnN")
colnames(buildDensity2018)
colnames(NTLBuild)
View(buildDensity2018)
View(NTLBuild)
#add in Building density *only for year 2016
buildDensity2016=gdriveURL("https://drive.google.com/open?id=11lPPduqiXIxz00fm6xxFzUA8u9nCOBnN")
#bringing in ntl buidling info for 2001-2004
NTLBuild<- read.csv("NTLBuildDensData(2001-2004).csv")
#fixing column names to join tables
NTLBuild$WBIC=NTLBuild$wbic
NTLBuild$surveyYear=NTLBuild$survey_year
NTLBuild<-NTLBuild[,c(1:4,8:34)]
#look at change in building density over time
#calculating buildings per km for 2016 data
buildDensity2016$buildings_per_km=buildDensity2016$buildingCount50m/(buildDensity2016$lakePerimeter_m*0.001)
colnames(buildDensity2016)
View(buildDensity2016)
#look at change in building density over time
#calculating buildings per km for 2016 data
buildDensity2016$buildings_per_km2016=buildDensity2016$buildingCount50m/(buildDensity2016$lakePerimeter_m*0.001)
buildDensCompare=left_join(buildDensity2016,NTLBuild, by="WBIC")
View(buildDensCompare)
buildDensCompare=full_join(buildDensity2016,NTLBuild, by="WBIC")
View(buildDensCompare)
buildDensCompare=buildDensCompare[!is.na(buildDensCompare$buildings_per_km.x)]
buildDensCompare=buildDensCompare[!is.na(buildDensCompare$buildings_per_km.x),]
View(buildDensCompare)
#look at change in building density over time
#calculating buildings per km for 2016 data
buildDensity2016$buildings_per_km2016=buildDensity2016$buildingCount50m/(buildDensity2016$lakePerimeter_m*0.001)
buildDensCompare=full_join(buildDensity2016,NTLBuild, by="WBIC")
buildDensCompare=buildDensCompare[!is.na(buildDensCompare$buildings_per_km.y),]
View(buildDensCompare)
plot(x=buildDensCompare$buildings_per_km.y,y=buildDensCompare$buildings_per_km.x, xlab= "NTL estiamte (2001-2004)"
ylab="2016 estimate (GIS)", main="Lake building density comparison of different years")
plot(x=buildDensCompare$buildings_per_km.y,y=buildDensCompare$buildings_per_km.x, xlab= "NTL estiamte (2001-2004)",
ylab="2016 estimate (GIS)", main="Lake building density comparison of different years")
ggplot(buildDensCompare, aes(x=x=buildDensCompare$buildings_per_km.y,y=buildDensCompare$buildings_per_km.x))+
geom_smooth()
library(ggplot2)
ggplot(data=buildDensCompare, aes(x=x=buildDensCompare$buildings_per_km.y,y=buildDensCompare$buildings_per_km.x))+
geom_smooth()
ggplot(data=buildDensCompare, aes(x=x=buildDensCompare$buildings_per_km.y,y=buildDensCompare$buildings_per_km.x))+
geom_smooth()
ggplot(data=buildDensCompare, aes(x=x=buildDensCompare$buildings_per_km.y,y=buildDensCompare$buildings_per_km.x))
ggplot(buildDensCompare, aes(x=x=buildDensCompare$buildings_per_km.y,y=buildDensCompare$buildings_per_km.x))
+geom_smooth()
ggplot(data=buildDensCompare, aes(x=buildDensCompare$buildings_per_km.y,y=buildDensCompare$buildings_per_km.x))
+geom_smooth()
ggplot(data=buildDensCompare, aes(x=buildDensCompare$buildings_per_km.y,y=buildDensCompare$buildings_per_km.x))+geom_smooth()
