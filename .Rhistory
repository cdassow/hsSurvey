for (i in 1:10){
if(i%%2==1) print(i)
}
?numeric
dim(iris)
ncol(iris)
nrow(iris)
oddRows<-function(x){
oddRows<-function(x){
oddRows<-function(x){
for (i in 1:nrow(x)) {
if(i%%2==1) oddFileRow<-print(i)
return(oddFileRow)
}
}
oddRows(iris)
setwd("C:/Users/jcaff/Documents/Notre Dame/Senior/fall_19/Biocomputing/R/Tutorial/Ex_07/ICB2019_Exercise07")
#loading iris.csv to iris
iris<-read.csv("iris.csv")
#loading iris.csv to iris
iris<-read.csv("iris.csv")
#loading iris.csv to iris
iris<-read.csv("iris.csv")
setwd("C:/Users/jcaff/Documents/Jones Lab/hsSurvey")
# load function to load data from google drive
source("gdriveURL.R")
library(dplyr)
creel1=gdriveURL("https://drive.google.com/open?id=1lxUd742QZMXDQunyFBnENKMYZ1XNM_Pc")
creel2=gdriveURL("https://drive.google.com/open?id=1UYhbGH28WXjmi-4BzhfwO4KYwrBCNO2Q")
creel=rbind(creel1,creel2)
# reduce to columns we care about
creel=creel[,c(1,3,6,12,18,25:26,30,36,38)]
# calculate effort
# add zeroes to times with only 2 or 3 digits
creel$timeStart[nchar(creel$timeStart)==3]=paste("0",creel$timeStart[nchar(creel$timeStart)==3],sep="")
creel$timeStart[nchar(creel$timeStart)==2]=paste("00",creel$timeStart[nchar(creel$timeStart)==2],sep="")
creel$timeStart[creel$timeStart=="0"]="0000"
creel=creel[creel$timeStart!="1",]  # 4 entries with "1", so we don't know start time
creel$timeEnd[nchar(creel$timeEnd)==3]=paste("0",creel$timeEnd[nchar(creel$timeEnd)==3],sep="")
creel$timeEnd[nchar(creel$timeStart)==2]=paste("00",creel$timeEnd[nchar(creel$timeEnd)==2],sep="")
creel$timeEnd[creel$timeEnd=="0"]="0000"
creel$boatHrs=0
# remove rows when end time is less than start time (assumes the boat was out over midnight)
creel=creel[strptime(creel$timeEnd,format="%H%M")>=strptime(creel$timeStart,format="%H%M"),]
# calculate difference of time in hours for rows where end time is greater than start time (fishing occurred in one day only)
creel$boatHrs[strptime(creel$timeEnd,format="%H%M")>=strptime(creel$timeStart,format="%H%M")]=as.numeric(difftime(strptime(creel$timeEnd[strptime(creel$timeEnd,format="%H%M")>=strptime(creel$timeStart,format="%H%M")],format="%H%M"),strptime(creel$timeStart[strptime(creel$timeEnd,format="%H%M")>=strptime(creel$timeStart,format="%H%M")],format="%H%M"),units="hours"))
# removing rows with a non-zero notFishingAmt because we don't know what it means to be non-zero...
creel=creel[creel$notFishingAmt==0,]
# remove rows with non-integer anglersAmt
creel=creel[!grepl(".",creel$anglersAmt,fixed=TRUE),]
# remove rows with anglersAmt above 10? (arbitrary choice for now)
creel=creel[creel$anglersAmt<=10,]
# get angler hours of effort from party size and boat hours
creel$anglerHrs=creel$boatHrs*creel$anglersAmt
# remove rows with no species code
creel=creel[!is.na(creel$fishSpeciesCode),]
# remove rows with NA for caughtAmt
creel=creel[!is.na(creel$caughtAmt),]
# remove no effort (anglerHrs==0) rows
creel=creel[creel$anglerHrs>0,]
# calculate angling CPUE
creel$anglingCPUE=creel$caughtAmt/creel$anglerHrs
# removing instances of CPUE >=30 (arbitrary...)
creel=creel[creel$anglingCPUE<30,]
# calculate average angling CPUE and sample size for each lake-year-species combination
lake_yearCPUE=creel %>%
group_by(WBIC,fishSpeciesCode,surveyYear,county) %>%
summarize(meanCPUE=mean(anglingCPUE),
N=n())
lake_yearCPUE=as.data.frame(lake_yearCPUE)
####### electrofishing abundance
bassEF=gdriveURL("https://drive.google.com/open?id=11v8FbT2wnKx_CqUfxu_V9r_8fyCfcdD2")
bassEF=bassEF[,c(1,3,5,13,19,27:29)]
bassEF$CPEkm=bassEF$CPEmile/1.60934   # convert fish per mile to fish per km
bassEF$distanceShockedKm=bassEF$distanceShockedMiles*0.621371 # convert miles to km
lake_yearBASSef= bassEF %>%
group_by(WBIC,species,surveyYear,county) %>%
summarize(meanEF_CPEkm=mean(CPEkm),
totalFishCaught=sum(totalNumberCaughtFish),
totalDistShockedKm=sum(distanceShockedKm),
totalHoursSampled=sum(numberHoursSampled),
std=sd(CPEkm),
N=n())
lake_yearBASSef=as.data.frame(lake_yearBASSef)
panEF=gdriveURL("https://drive.google.com/open?id=1QIqCBQ9gbOgRFUJQbnokwwTZJi5VZZIR")
panEF=panEF[,c(1,3,5,13,19,25:27)]
panEF$CPEkm=panEF$CPEmile/1.60934   # convert fish per mile to fish per km
panEF$distanceShockedKm=panEF$distanceShockedMiles*0.621371 # convert miles to km
lake_yearPANef= panEF %>%
group_by(WBIC,species,surveyYear,county) %>%
summarize(meanEF_CPEkm=mean(CPEkm),
totalFishCaught=sum(totalNumberCaughtFish),
totalDistShockedKm=sum(distanceShockedKm),
totalHoursSampled=sum(numberHoursSampled),
std=sd(CPEkm),
N=n())
lake_yearPANef=as.data.frame(lake_yearPANef)
walleyeEF=gdriveURL("https://drive.google.com/open?id=1DPRROWv6Cf_fP6Z-kE9ZgUfdf_F_jSNT")
walleyeEF=walleyeEF[,c(1,3,5,13,19,23:24,27)]
walleyeEF$CPEkm=walleyeEF$CPEmile/1.60934   # convert fish per mile to fish per km
walleyeEF$distanceShockedKm=walleyeEF$distanceShockedMiles*0.621371 # convert miles to km
#remove commas from total fish caught
walleyeEF$totalNumberCaughtFish=as.numeric(gsub(",","",walleyeEF$totalNumberCaughtFish))
lake_yearWALLef= walleyeEF %>%
group_by(WBIC,species,surveyYear,county) %>%
summarize(meanEF_CPEkm=mean(CPEkm),
totalFishCaught=sum(totalNumberCaughtFish),
totalDistShockedKm=sum(distanceShockedKm),
totalHoursSampled=sum(numberHoursSampled),
std=sd(CPEkm),
N=n())
lake_yearWALLef=as.data.frame(lake_yearWALLef)
##### merge data sets from angling CPUE and electrofishing CPUE to get exact lake-year matches
# convert fishSpeciesCode in lake_yearCPUE to species (name from ef stuff)
lake_yearCPUE$species=""
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="X22"]="WALLEYE"
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="W11"]="SMALLMOUTH BASS"
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="W12"]="LARGEMOUTH BASS"
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="X15"]="YELLOW PERCH"
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="W14"]="BLACK CRAPPIE"
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="W09"]="BLUEGILL"
# trim species without EF data (can we get other species EF data?)
lake_yearCPUE=lake_yearCPUE[lake_yearCPUE$species!="",]
bassJoin=left_join(lake_yearBASSef,lake_yearCPUE,by=c("WBIC"="WBIC","species"="species","surveyYear"="surveyYear", "county"="county"))
bassJoin=bassJoin[!is.na(bassJoin$meanCPUE),]
panJoin=left_join(lake_yearPANef,lake_yearCPUE,by=c("WBIC"="WBIC","species"="species","surveyYear"="surveyYear", "county"="county"))
panJoin=panJoin[!is.na(panJoin$meanCPUE),]
wallJoin=left_join(lake_yearWALLef,lake_yearCPUE,by=c("WBIC"="WBIC","species"="species","surveyYear"="surveyYear", "county"="county"))
wallJoin=wallJoin[!is.na(wallJoin$meanCPUE),]
table(lake_yearCPUE$species)
nrow(lake_yearBASSef)
nrow(bassJoin)
nrow(lake_yearPANef)
nrow(panJoin)
nrow(lake_yearWALLef)
nrow(wallJoin)
# load function to load data from google drive
source("gdriveURL.R")
library(dplyr)
######## angling CPUE
# load creel data from google drive
creel1=gdriveURL("https://drive.google.com/open?id=1lxUd742QZMXDQunyFBnENKMYZ1XNM_Pc")
creel2=gdriveURL("https://drive.google.com/open?id=1UYhbGH28WXjmi-4BzhfwO4KYwrBCNO2Q")
creel=rbind(creel1,creel2)
creel=creel[,c(1,3,6,12,18,25:26,30,36,38)]
# calculate effort
# add zeroes to times with only 2 or 3 digits
creel$timeStart[nchar(creel$timeStart)==3]=paste("0",creel$timeStart[nchar(creel$timeStart)==3],sep="")
creel$timeStart[nchar(creel$timeStart)==2]=paste("00",creel$timeStart[nchar(creel$timeStart)==2],sep="")
creel$timeStart[creel$timeStart=="0"]="0000"
creel=creel[creel$timeStart!="1",]  # 4 entries with "1", so we don't know start time
creel$timeEnd[nchar(creel$timeEnd)==3]=paste("0",creel$timeEnd[nchar(creel$timeEnd)==3],sep="")
creel$timeEnd[nchar(creel$timeStart)==2]=paste("00",creel$timeEnd[nchar(creel$timeEnd)==2],sep="")
creel$timeEnd[creel$timeEnd=="0"]="0000"
creel$boatHrs=0
# remove rows when end time is less than start time (assumes the boat was out over midnight)
creel=creel[strptime(creel$timeEnd,format="%H%M")>=strptime(creel$timeStart,format="%H%M"),]
# calculate difference of time in hours for rows where end time is greater than start time (fishing occurred in one day only)
creel$boatHrs[strptime(creel$timeEnd,format="%H%M")>=strptime(creel$timeStart,format="%H%M")]=as.numeric(difftime(strptime(creel$timeEnd[strptime(creel$timeEnd,format="%H%M")>=strptime(creel$timeStart,format="%H%M")],format="%H%M"),strptime(creel$timeStart[strptime(creel$timeEnd,format="%H%M")>=strptime(creel$timeStart,format="%H%M")],format="%H%M"),units="hours"))
# removing rows with a non-zero notFishingAmt because we don't know what it means to be non-zero...
creel=creel[creel$notFishingAmt==0,]
# remove rows with non-integer anglersAmt
creel=creel[!grepl(".",creel$anglersAmt,fixed=TRUE),]
# remove rows with anglersAmt above 10? (arbitrary choice for now)
creel=creel[creel$anglersAmt<=10,]
# get angler hours of effort from party size and boat hours
creel$anglerHrs=creel$boatHrs*creel$anglersAmt
# remove rows with no species code
creel=creel[!is.na(creel$fishSpeciesCode),]
# remove rows with NA for caughtAmt
creel=creel[!is.na(creel$caughtAmt),]
# remove no effort (anglerHrs==0) rows
creel=creel[creel$anglerHrs>0,]
# calculate angling CPUE
creel$anglingCPUE=creel$caughtAmt/creel$anglerHrs
# removing instances of CPUE >=30 (arbitrary...)
creel=creel[creel$anglingCPUE<30,]
# calculate average angling CPUE and sample size for each lake-year-species combination
lake_yearCPUE=creel %>%
group_by(WBIC,fishSpeciesCode,surveyYear,county) %>%
summarize(meanCPUE=mean(anglingCPUE),
N=n())
lake_yearCPUE=as.data.frame(lake_yearCPUE)
####### electrofishing abundance
bassEF=gdriveURL("https://drive.google.com/open?id=11v8FbT2wnKx_CqUfxu_V9r_8fyCfcdD2")
bassEF=bassEF[,c(1,3,5,13,19,27:29)]
bassEF$CPEkm=bassEF$CPEmile/1.60934   # convert fish per mile to fish per km
bassEF$distanceShockedKm=bassEF$distanceShockedMiles*0.621371 # convert miles to km
lake_yearBASSef= bassEF %>%
group_by(WBIC,species,surveyYear,county) %>%
summarize(meanEF_CPEkm=mean(CPEkm),
totalFishCaught=sum(totalNumberCaughtFish),
totalDistShockedKm=sum(distanceShockedKm),
totalHoursSampled=sum(numberHoursSampled),
std=sd(CPEkm),
N=n())
lake_yearBASSef=as.data.frame(lake_yearBASSef)
panEF=gdriveURL("https://drive.google.com/open?id=1QIqCBQ9gbOgRFUJQbnokwwTZJi5VZZIR")
panEF=panEF[,c(1,3,5,13,19,25:27)]
panEF$CPEkm=panEF$CPEmile/1.60934   # convert fish per mile to fish per km
panEF$distanceShockedKm=panEF$distanceShockedMiles*0.621371 # convert miles to km
lake_yearPANef= panEF %>%
group_by(WBIC,species,surveyYear,county) %>%
summarize(meanEF_CPEkm=mean(CPEkm),
totalFishCaught=sum(totalNumberCaughtFish),
totalDistShockedKm=sum(distanceShockedKm),
totalHoursSampled=sum(numberHoursSampled),
std=sd(CPEkm),
N=n())
lake_yearPANef=as.data.frame(lake_yearPANef)
walleyeEF=gdriveURL("https://drive.google.com/open?id=1DPRROWv6Cf_fP6Z-kE9ZgUfdf_F_jSNT")
walleyeEF=walleyeEF[,c(1,3,5,13,19,23:24,27)]
walleyeEF$CPEkm=walleyeEF$CPEmile/1.60934   # convert fish per mile to fish per km
walleyeEF$distanceShockedKm=walleyeEF$distanceShockedMiles*0.621371 # convert miles to km
#remove commas from total fish caught
walleyeEF$totalNumberCaughtFish=as.numeric(gsub(",","",walleyeEF$totalNumberCaughtFish))
lake_yearWALLef= walleyeEF %>%
group_by(WBIC,species,surveyYear,county) %>%
summarize(meanEF_CPEkm=mean(CPEkm),
totalFishCaught=sum(totalNumberCaughtFish),
totalDistShockedKm=sum(distanceShockedKm),
totalHoursSampled=sum(numberHoursSampled),
std=sd(CPEkm),
N=n())
lake_yearWALLef=as.data.frame(lake_yearWALLef)
##### merge data sets from angling CPUE and electrofishing CPUE to get exact lake-year matches
# convert fishSpeciesCode in lake_yearCPUE to species (name from ef stuff)
lake_yearCPUE$species=""
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="X22"]="WALLEYE"
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="W11"]="SMALLMOUTH BASS"
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="W12"]="LARGEMOUTH BASS"
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="X15"]="YELLOW PERCH"
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="W14"]="BLACK CRAPPIE"
lake_yearCPUE$species[lake_yearCPUE$fishSpeciesCode=="W09"]="BLUEGILL"
# trim species without EF data (can we get other species EF data?)
lake_yearCPUE=lake_yearCPUE[lake_yearCPUE$species!="",]
bassJoin=left_join(lake_yearBASSef,lake_yearCPUE,by=c("WBIC"="WBIC","species"="species","surveyYear"="surveyYear", "county"="county"))
bassJoin=bassJoin[!is.na(bassJoin$meanCPUE),]
panJoin=left_join(lake_yearPANef,lake_yearCPUE,by=c("WBIC"="WBIC","species"="species","surveyYear"="surveyYear", "county"="county"))
panJoin=panJoin[!is.na(panJoin$meanCPUE),]
wallJoin=left_join(lake_yearWALLef,lake_yearCPUE,by=c("WBIC"="WBIC","species"="species","surveyYear"="surveyYear", "county"="county"))
wallJoin=wallJoin[!is.na(wallJoin$meanCPUE),]
table(lake_yearCPUE$species)
nrow(lake_yearBASSef)
nrow(bassJoin)
nrow(lake_yearPANef)
nrow(panJoin)
nrow(lake_yearWALLef)
nrow(wallJoin)
library(ggplot2)
####### Hyperstability (abund and CPUE plots) #####
#ploting and colors based on wbic, for bass 1-4 plots
ggplot(data=bassJoin,aes(x=bassJoin$meanEF_CPEkm,y=bassJoin$meanCPUE))+
geom_point(aes(color=WBIC))
#smooth line making trendline of observations
ggplot(data=bassJoin,aes(x=bassJoin$meanEF_CPEkm,y=bassJoin$meanCPUE))+
geom_smooth(model=lm)
#connecting with line
ggplot(data=bassJoin,aes(x=bassJoin$meanEF_CPEkm,y=bassJoin$meanCPUE))+
geom_line()
#color coded by LMB or SMB
ggplot(data=bassJoin,aes(x=bassJoin$meanEF_CPEkm,y=bassJoin$meanCPUE))+
geom_point(aes(color=species))+theme(legend.position = "right")
#ploting for walleye population
ggplot(data=wallJoin,aes(x=wallJoin$meanEF_CPEkm,y=wallJoin$meanCPUE))+
geom_smooth(model=lm)
ggplot(data=wallJoin,aes(x=wallJoin$meanEF_CPEkm,y=wallJoin$meanCPUE))+
geom_line()
ggplot(data=wallJoin,aes(x=wallJoin$meanEF_CPEkm,y=wallJoin$meanCPUE))+
geom_point()
#plotting for panfish species
ggplot(data=panJoin,aes(x=panJoin$meanEF_CPEkm,y=panJoin$meanCPUE))+
geom_point(aes(color=species))+theme(legend.position = "right")
######## log values and model fits #######
#creating log CPUE and log N columns, removing na's and infinite values so glm can run and we can make fit
bassJoin$logCPUE=log(bassJoin$meanCPUE)
bassJoin$logAbun=log(bassJoin$meanEF_CPEkm)
bassJoin<- bassJoin[is.na(bassJoin$logCPUE)==F,]
bassJoin<- bassJoin[bassJoin$logCPUE!=-Inf,]
wallJoin$logCPUE=log(wallJoin$meanCPUE)
wallJoin$logAbun=log(wallJoin$meanEF_CPEkm)
wallJoin<- wallJoin[wallJoin$logCPUE!=-Inf,]
panJoin$logCPUE=log(panJoin$meanCPUE)
panJoin$logAbun=log(panJoin$meanEF_CPEkm)
panJoin<- panJoin[panJoin$logCPUE!=-Inf,]
#making upper and lower confidence intervals using std and the mean to helep with measuring betas
bassJoin$PE.ucl=bassJoin$std+bassJoin$meanCPUE
bassJoin$PE.lcl=bassJoin$std-bassJoin$meanCPUE
wallJoin$PE.ucl=wallJoin$std+wallJoin$meanCPUE
wallJoin$PE.lcl=wallJoin$std-wallJoin$meanCPUE
panJoin$PE.ucl=panJoin$std+panJoin$meanCPUE
panJoin$PE.lcl=panJoin$std-panJoin$meanCPUE
#join tables to compare species with lm model
LMBplusWall=rbind(bassJoin[bassJoin$species=="LARGEMOUTH BASS",],wallJoin)
#generate linear model to compare hyperstability of
LMBvsWall<-lm(LMBplusWall$logCPUE~LMBplusWall$logAbun*LMBplusWall$species)
summary(LMBvsWall)
#Walleye statistically significant different from LMB hyperstability similar lines on fit
#bringing in CWH data from ntl data 2001-2004
ntlCWH=read.csv("ntl125_2_v1_0.csv")
#reducing columns to lake name, lake id, log present
ntlCWH<-ntlCWH[,c(1,2,9)]
#assigning numeric values to logs present
ntlCWH=ntlCWH %>%
mutate(numLog=recode(ntlCWH$type,"LOG"=1))
#replacing NA's with 0 in the numLog column
ntlCWH=ntlCWH[is.na(ntlCWH$numLog)==FALSE,]
#summing observations by lake name
lakeCWH=aggregate(ntlCWH$numLog,by=list(lakename=ntlCWH$lakename),FUN=sum)
##using linfo to add WBICS to CWH counts
linfo<-gdriveURL("https://drive.google.com/open?id=1ot9rEYnCG07p7aUxbeqN2mJ3cNrzYA0Y")
linfo=linfo[,1:13]
#check line to get all 3 columns
lakeName<-linfo[,c(1:2,14)]
lakeNameVilas<-lakeName[lakeName$county=="Vilas",]
lakeNameVilas<-lakeNameVilas[,c(1,2)]
colnames(lakeNameVilas)<-c("WBIC","lakename")
lakeCWHVilas<-left_join(lakeCWH,lakeNameVilas,by="lakename")
#calculating Log/KMshoreline as CWH density
for(i in (1:nrow(lakeCWHVilas))){
lakeCWHVilas$CWHkm[i]<-lakeCWHVilas$x[i]/0.4
}
VilasCWHperKM<-lakeCWHVilas[,c(3,4)]
lakeCWHVilas<-left_join(lakeCWH,lakeNameVilas,by="lakename")
lakeNameVilas<-lakeName[lakeName$county=="Vilas",]
#check line to get all 3 columns
lakeName<-linfo[,c(1:2,14)]
#check line to get all 3 columns
lakeName<-linfo[,c(1,2,14)]
lakeNameVilas<-lakeName[lakeName$county=="Vilas",]
#check line to get all 3 columns
lakeName<-linfo[,c(1,2,14)]
View(linfo)
#check line to get all 3 columns
lakeName<-linfo[,c(1,2)]
lakeNameVilas<-lakeName[lakeName$county=="Vilas",]
lakeNameVilas<-lakeNameVilas[,c(1,2)]
colnames(lakeNameVilas)<-c("WBIC","lakename")
lakeCWHVilas<-left_join(lakeCWH,lakeNameVilas,by="lakename")
#calculating Log/KMshoreline as CWH density
for(i in (1:nrow(lakeCWHVilas))){
lakeCWHVilas$CWHkm[i]<-lakeCWHVilas$x[i]/0.4
}
VilasCWHperKM<-lakeCWHVilas[,c(3,4)]
#joining to tables
bassCWHJoin=left_join(bassJoin,VilasCWHperKM,by="WBIC")
bassCWHJoin=bassCWHJoin[!is.na(bassCWHJoin$CWHkm),]
View(bassCWHJoin)
View(lakeNameVilas)
#bringing in CWH data from ntl data 2001-2004
ntlCWH=read.csv("ntl125_2_v1_0.csv")
#reducing columns to lake name, lake id, log present
ntlCWH<-ntlCWH[,c(1,2,9)]
#assigning numeric values to logs present
ntlCWH=ntlCWH %>%
mutate(numLog=recode(ntlCWH$type,"LOG"=1))
#replacing NA's with 0 in the numLog column
ntlCWH=ntlCWH[is.na(ntlCWH$numLog)==FALSE,]
#summing observations by lake name
lakeCWH=aggregate(ntlCWH$numLog,by=list(lakename=ntlCWH$lakename),FUN=sum)
##using linfo to add WBICS to CWH counts
linfo<-gdriveURL("https://drive.google.com/open?id=1ot9rEYnCG07p7aUxbeqN2mJ3cNrzYA0Y")
linfo=linfo[,1:13]
#check line to get all 3 columns
lakeName<-linfo[,c(1,2)]
lakeNameVilas<-lakeName[lakeName$county=="Vilas",]
lakeNameVilas<-lakeNameVilas[,c(1,2)]
linfo=linfo[,1:14]
##using linfo to add WBICS to CWH counts
linfo<-gdriveURL("https://drive.google.com/open?id=1ot9rEYnCG07p7aUxbeqN2mJ3cNrzYA0Y")
View(linfo)
View(linfo)
linfo=linfo[,1:14]
#check line to get all 3 columns
lakeName<-linfo[,c(1,2,14)]
lakeNameVilas<-lakeName[lakeName$county=="Vilas",]
lakeNameVilas<-lakeNameVilas[,c(1,2)]
colnames(lakeNameVilas)<-c("WBIC","lakename")
lakeCWHVilas<-left_join(lakeCWH,lakeNameVilas,by="lakename")
#calculating Log/KMshoreline as CWH density
for(i in (1:nrow(lakeCWHVilas))){
lakeCWHVilas$CWHkm[i]<-lakeCWHVilas$x[i]/0.4
}
VilasCWHperKM<-lakeCWHVilas[,c(3,4)]
#joining to tables
bassCWHJoin=left_join(bassJoin,VilasCWHperKM,by="WBIC")
bassCWHJoin=bassCWHJoin[!is.na(bassCWHJoin$CWHkm),]
View(bassCWHJoin)
#joining to tables
bassCWHJoin=left_join(bassJoin,VilasCWHperKM,by="WBIC")
bassCWHJoin=bassCWHJoin[!is.na(bassCWHJoin$CWHkm),]
wallCWHJoin=left_join(wallJoin,VilasCWHperKM,by="WBIC")
wallCWHJoin=wallCWHJoin[!is.na(wallCWHJoin$CWHkm),]
panCWHJoin=left_join(panJoin,VilasCWHperKM,by="WBIC")
panCWHJoin=panCWHJoin[!is.na(panCWHJoin$CWHkm),]
#joining to tables
bassCWHJoin=left_join(bassJoin,VilasCWHperKM,by="WBIC")
View(bassCWHJoin)
View(VilasCWHperKM)
#bringing in CWH data from ntl data 2001-2004
ntlCWH=read.csv("ntl125_2_v1_0.csv")
#reducing columns to lake name, lake id, log present
ntlCWH<-ntlCWH[,c(1,2,9)]
#assigning numeric values to logs present
ntlCWH=ntlCWH %>%
mutate(numLog=recode(ntlCWH$type,"LOG"=1))
View(ntlCWH)
#replacing NA's with 0 in the numLog column
ntlCWH=ntlCWH[is.na(ntlCWH$numLog)=0,]
#replacing NA's with 0 in the numLog column
ntlCWH=ntlCWH[is.na(ntlCWH$numLog)]=0
ntlCWH[is.na(ntlCWH$numLog)]=0
ntlCWH$numLog[is.na(ntlCWH$numLog)]=0
#summing observations by lake name
lakeCWH=aggregate(ntlCWH$numLog,by=list(lakename=ntlCWH$lakename),FUN=sum)
View(lakeCWH)
##using linfo to add WBICS to CWH counts
linfo<-gdriveURL("https://drive.google.com/open?id=1ot9rEYnCG07p7aUxbeqN2mJ3cNrzYA0Y")
linfo=linfo[,1:14]
#check line to get all 3 columns
lakeName<-linfo[,c(1,2,14)]
lakeNameVilas<-lakeName[lakeName$county=="Vilas",]
lakeNameVilas<-lakeNameVilas[,c(1,2)]
colnames(lakeNameVilas)<-c("WBIC","lakename")
View(lakeNameVilas)
lakeCWHVilas<-left_join(lakeCWH,lakeNameVilas,by="lakename")
View(lakeCWHVilas)
View(linfo)
#manually entering WBIC's for few NA's
lakeCWHVilas[9,lakeCWHVilas$WBIC]=1591100
lakeCWHVilas[9,is.na(lakeCWHVilas$WBIC)]=1591100
lakeCWHVilas$WBIC[9,is.na(lakeCWHVilas$WBIC)]=1591100
#manually entering WBIC's for few NA's
lakeCWHVilas$WBIC[is.na(lakeCWHVilas$WBIC)]=0
lakeCWHVilas$WBIC[9,3]=1591100
lakeCWHVilas<-as.data.frame(lakeCWHVilas)
lakeCWHVilas$WBIC[9,3]=1591100
lakeCWHVilas[9,3]=1591100
lakeCWHVilas[28,3]=2766200
lakeCWHVilas[37,3]=1596300
lakeCWHVilas[52,3]=1872100
#Little Rock Combination
lakeCWHVilas[34,2]=127
lakeCWHVilas[34,3]=1862100
#calculating Log/KMshoreline as CWH density
for(i in (1:nrow(lakeCWHVilas))){
lakeCWHVilas$CWHkm[i]<-lakeCWHVilas$x[i]/0.4
}
VilasCWHperKM<-lakeCWHVilas[,c(3,4)]
View(VilasCWHperKM)
#joining to tables
bassCWHJoin=left_join(bassJoin,VilasCWHperKM,by="WBIC")
View(bassCWHJoin)
bassCWHJoin=bassCWHJoin[!is.na(bassCWHJoin$CWHkm),]
wallCWHJoin=left_join(wallJoin,VilasCWHperKM,by="WBIC")
wallCWHJoin=wallCWHJoin[!is.na(wallCWHJoin$CWHkm),]
panCWHJoin=left_join(panJoin,VilasCWHperKM,by="WBIC")
panCWHJoin=panCWHJoin[!is.na(panCWHJoin$CWHkm),]
bassCWHJoinVilas<-bassCWHJoinVilas[,bassCWHJoin$county="VILAS"]
bassCWHJoinVilas<-bassCWHJoinVilas[,bassCWHJoin$county=="VILAS"]
bassCWHJoinVilas<-bassCWHJoin[,bassCWHJoin$county=="VILAS"]
bassCWHJoinVilas<-bassCWHJoin[bassCWHJoin$county=="VILAS"]
bassCWHJoinVilas<-bassCWHJoin[bassCWHJoin$county=="VILAS",]
View(bassCWHJoin)
View(bassJoin)
bassJoinVilas<-bassJoin[bassJoin$county=="VILAS",]
View(bassJoinVilas)
#2001-2016 subset
bassCWHJoin0116<-bassCWHJoin[bassCWHJoin$surveyYear==2001:2016,]
View(bassCWHJoin0116)
View(bassCWHJoin)
#2001-2016 subset
bassCWHJoin0116<-bassCWHJoin[bassCWHJoin$surveyYear=2001:2016,]
#2001-2016 subset
bassCWHJoin0116<-bassCWHJoin[bassCWHJoin$surveyYear>2000 & bassCWHJoin$surveyYear<2017,]
View(bassCWHJoin0116)
wallCWHJoin0116<-wallCWHJoin[wallCWHJoin$surveyYear>2000 & wallCWHJoin$surveyYear<2017,]
panCWHJoin0116<-panCWHJoin[panCWHJoin$surveyYear>2000 & panCWHJoin$surveyYear<2017,]
#2001-2004 subset
bassCWHJoin0104<-bassCWHJoin[bassCWHJoin$surveyYear>2000 & bassCWHJoin$surveyYear<2005,]
View(bassCWHJoin0116)
View(bassCWHJoin0104)
wallCWHJoin0104<-wallCWHJoin[wallCWHJoin$surveyYear>2000 & wallCWHJoin$surveyYear<2005,]
panCWHJoin0104<-panCWHJoin[panCWHJoin$surveyYear>2000 & panCWHJoin$surveyYear<2005,]
